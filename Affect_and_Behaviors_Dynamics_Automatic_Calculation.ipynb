{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN3UzyssGSUKyXI41UxmAZf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/felipmorais/Affect-and-Behaviors-Dynamics-Automatic-Calculation---PhD-Dissertation/blob/main/Affect_and_Behaviors_Dynamics_Automatic_Calculation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis of the dynamics between emotions and behaviors in the Brazilian context\n",
        "---\n",
        "\n",
        "\n",
        "This code was developed to calculate the dynamics between affect and behaviors. It computes three different types of calculations: The first one calculates the probability of an emotion to be the reason for the onset of a behavior. The second one calculates the opposite, i.e., the probability of a behavior to be the reason for the onset of an emotion. And, the third one calculates the co-occurrence probability, i.e., the probability of a given behavior and a given emotion to occurr at the same time. Unlike other open-source code, this code is designed to:\n",
        "\n",
        "1. Calculate the adjusted L metric;\n",
        "2. Apply a t-test to calculate the statistical significance of the results considering all students;\n",
        "3. Apply the p-value adjustment calculation for multiple tests, considering the Benjamini/Hochberg (BH) method;\n",
        "4. Print calculated statistics in tabular form;\n",
        "5. Compute the dynamics between affect and behaviors \n",
        "6. Compute the dynamics between behaviors and affect  \n",
        "7. Compute the co-occurrence between behaviors and affect\n",
        "* Items 5, 6, and 7 are based on calculated statistics, considering only transitions reported as significant after p-value adjustment based on BH method; Also, these items include the analysis when considering the students gender.\n",
        "\n",
        "\n",
        "---\n",
        "**Important:** This code is part of a scientific article submitted for evaluation.\n",
        "*Please do not share this code until the article is published.*"
      ],
      "metadata": {
        "id": "7l8Q7BAJUPMT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execution 1: Lib imports and data files load\n",
        "---\n",
        "This code is used to import and pre-process the emotions file. It is important that this file is ordered according to the occurrence of emotions and the id of the respective student. It also loads the file with the emotions permanence time.\n"
      ],
      "metadata": {
        "id": "oNtcIIwsUlD0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sdRlUG0YyDz",
        "outputId": "d1622a5d-d5df-486c-abe3-49467cf4ac15"
      },
      "source": [
        "# libs import and file loader\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "from scipy import stats\n",
        "from scipy.stats import shapiro\n",
        "import statsmodels.stats.multitest as multi\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import networkx as nx\n",
        "import statistics\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# file with all logs with emotion labels\n",
        "# CSV Data example:\n",
        "# student_id,emotion_label,behavior_label\n",
        "# 1,ENGAGEMENT,ON TASK\n",
        "# 1,ENGAGEMENT,ON TASK\n",
        "# 1,CONFUSION,ON TASK\n",
        "# 1,CONFUSION,ON TASK\n",
        "# 1,CONFUSION,ON TASK\n",
        "# 1,CONFUSION,ON TASK CONVERSATION\n",
        "# 1,CONFUSION,ON TASK CONVERSATION\n",
        "# 1,CONFUSION,ON TASK CONVERSATION\n",
        "# 1,BOREDOM,ON TASK\n",
        "# 1,BOREDOM,ON TASK\n",
        "# 1,BOREDOM,ON TASK\n",
        "# 1,BOREDOM,ON SYSTEM\n",
        "# 1,BOREDOM,ON SYSTEM\n",
        "# 1,BOREDOM,ON SYSTEM\n",
        "# 1,FRUSTRATION,ON TASK\n",
        "# 1,FRUSTRATION,ON TASK\n",
        "# 1,FRUSTRATION,ON TASK\n",
        "# 1,ENGAGEMENT,ON TASK\n",
        "# 1,ENGAGEMENT,ON TASK\n",
        "# 1,ENGAGEMENT,ON TASK\n",
        "# 1,ENGAGEMENT,ON TASK\n",
        "affect_and_behavior_labels_path = \"/content/drive/MyDrive/<PATH_TO_THE_AFFECT_AND_BEHAVIORS_LABELS_FILE>.csv\"\n",
        "df_labels = pd.read_csv(affect_and_behavior_labels_path, delimiter=\",\")\n",
        "\n",
        "\n",
        "# students information about gender\n",
        "# CSV data example:\n",
        "# student_id,gender\n",
        "# 1,F\n",
        "# 2,F\n",
        "# 3,M\n",
        "# 4,M\n",
        "# 5,M\n",
        "# 6,F\n",
        "# 7,M\n",
        "students_info_path = \"/content/drive/MyDrive/<PATH_TO_THE_STUDENTS_INFO_FILE>.csv\"\n",
        "df_students_info = pd.read_csv(students_info_path, delimiter=\",\")\n",
        "\n",
        "# file with the emotion duration (permanence time in each emotion) in seconds of the students\n",
        "# CSV data example:\n",
        "# student_id,emotion_label,duration\n",
        "# 1,ENGAGEMENT,12\n",
        "# 1,OTHER,2\n",
        "# 1,ENGAGEMENT,19\n",
        "# 1,OTHER,2\n",
        "# 1,ENGAGEMENT,12\n",
        "# 1,FRUSTRATION,2\n",
        "# 1,ENGAGEMENT,4\n",
        "# 1,CONFUSION,2\n",
        "# 1,ENGAGEMENT,34\n",
        "# 1,OTHER,15\n",
        "# 1,ENGAGEMENT,13\n",
        "# 1,CONFUSION,17\n",
        "# 1,FRUSTRATION,3\n",
        "emotions_duration_path = \"/content/drive/MyDrive/<PATH_TO_THE_EMOTIONS_DURAION_FILE>.csv\"\n",
        "df_emotions_duration = pd.read_csv(emotions_duration_path, delimiter=\",\")\n",
        "\n",
        "# data preparation for the log files\n",
        "df_labels.loc[df_labels.emotion_label == \"FRUSTRATION\", \"emotion_label\"] = \"FRU\"\n",
        "df_labels.loc[df_labels.emotion_label == \"ENGAGEMENT\", \"emotion_label\"] = \"ENG\"\n",
        "df_labels.loc[df_labels.emotion_label == \"CONFUSION\", \"emotion_label\"] = \"CON\"\n",
        "df_labels.loc[df_labels.emotion_label == \"BOREDOM\", \"emotion_label\"] = \"BOR\"\n",
        "df_labels.loc[df_labels.emotion_label == \"OTHER\", \"emotion_label\"] = \"OTH\"\n",
        "# remove na lines from the null emotion labels \n",
        "df_labels = df_labels[df_labels.emotion_label.notna()]\n",
        "\n",
        "# data preparation for the log files\n",
        "df_labels.loc[df_labels.behavior_label == \"ON TASK\", \"behavior_label\"] = \"ON_TASK\"\n",
        "df_labels.loc[df_labels.behavior_label == \"ON SYSTEM\", \"behavior_label\"] = \"ON_SYSTEM\"\n",
        "df_labels.loc[df_labels.behavior_label == \"ON TASK RESOURCE\", \"behavior_label\"] = \"ON_TASK_RES\"\n",
        "df_labels.loc[df_labels.behavior_label == \"OFF TASK\", \"behavior_label\"] = \"OFF_TASK\"\n",
        "df_labels.loc[df_labels.behavior_label == \"ON TASK CONVERSATION\", \"behavior_label\"] = \"ON_TASK_CONV\"\n",
        "# remove na lines from the null emotion labels \n",
        "df_labels = df_labels[df_labels.behavior_label.notna()]\n",
        "\n",
        "# data preparation for the emotion duration file\n",
        "df_emotions_duration.loc[df_emotions_duration.emotion_label == \"FRUSTRATION\", \"emotion_label\"] = \"FRU\"\n",
        "df_emotions_duration.loc[df_emotions_duration.emotion_label == \"ENGAGEMENT\", \"emotion_label\"] = \"ENG\"\n",
        "df_emotions_duration.loc[df_emotions_duration.emotion_label == \"CONFUSION\", \"emotion_label\"] = \"CON\"\n",
        "df_emotions_duration.loc[df_emotions_duration.emotion_label == \"BOREDOM\", \"emotion_label\"] = \"BOR\"\n",
        "df_emotions_duration.loc[df_emotions_duration.emotion_label == \"OTHER\", \"emotion_label\"] = \"OTH\"\n",
        "# remove na lines from the null emotion labels \n",
        "df_emotions_duration = df_emotions_duration[df_emotions_duration.emotion_label.notna()]\n",
        "\n",
        "# define which emotions will be considered and in which order\n",
        "emotions_list = ['ENG', 'CON', 'FRU', 'BOR', 'OTH']\n",
        "behaviors_list = ['ON_TASK', 'ON_SYSTEM', 'ON_TASK_RES', 'OFF_TASK', 'ON_TASK_CONV']\n",
        "emotions_behaviors_list = emotions_list + behaviors_list\n",
        "\n",
        "# define the metrics that will be visible when the resulting table is printed\n",
        "table_metrics_to_print = ['L_metric','p_value','transition_count','multiple_test_significance']\n",
        "\n",
        "# define the at chance level when the emotions' co-occurence is removed from the data\n",
        "# this value was defined according to the paper \"A Re-Analysis and Synthesis of Data on Affect Dynamics in Learning\", by Shamya Karumbaiah, Ryan Baker, Jaclyn Ocumpaugh, and Alexandra Andres\n",
        "# it follows the formula: 1 / (n - 1)^2, in which n is the number of considered emotions. In this case, we have considered 5 emotions: 'ENG', 'CON', 'FRU', 'BOR', 'OTH'\n",
        "L_metric_at_chance_threshold=0.0625\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1817: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_column(loc, value, pi)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execution 2: L metric calculation methods\n",
        "---\n",
        "This first code is imported from the article \"Adjusting the L Statistic when Self-Transitions are Excluded in Affect Dynamics\", by authors Jeffrey Matayoshi and Shamya Karumbaiah, 2020.\n",
        "\n",
        "The code has been kept completely for simplicity. Howeber, we have changed some methods in order to deal with the additional information about permanence time and to bring the list of all L-values to the t-test application, for the p-value calculation."
      ],
      "metadata": {
        "id": "FtpOn1_UU2n4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75jSFTnyZb5K"
      },
      "source": [
        "# code from https://github.com/jmatayoshi/affect-transitions\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def remove_self_transitions(seq):\n",
        "  return [st for i, st in enumerate(seq) if i == 0 or st != seq[i - 1]]\n",
        "\n",
        "def remove_behavior_self_transitions(seq):\n",
        "  return [st for i, st in enumerate(seq) if i == 0 or st != seq[i - 1]]\n",
        "\n",
        "def generate_sequence(seq_length, state_dict, base_rates,\n",
        "                      include_self_transitions=True):\n",
        "    state_ind = np.arange(len(state_dict))\n",
        "    if include_self_transitions:\n",
        "        seq = list(\n",
        "            np.random.choice(\n",
        "                list(state_dict.values()),\n",
        "                size=seq_length,\n",
        "                p=base_rates\n",
        "            )\n",
        "        )\n",
        "    else:\n",
        "        base_rates = np.array(base_rates)\n",
        "        # Construct mapping from each state to its index in state_dict\n",
        "        inv_state_dict = {}\n",
        "        for i in range(len(state_dict)):\n",
        "            inv_state_dict[state_dict[i]] = i\n",
        "        # Sample first state\n",
        "        seq = [state_dict[np.random.multinomial(1, base_rates).argmax()]] \n",
        "        for i in range(seq_length - 1):\n",
        "            # Get index of previous state\n",
        "            prev_ind = inv_state_dict[seq[-1]]\n",
        "            # Get indices of possible next states\n",
        "            next_ind = np.setdiff1d(state_ind, [prev_ind])\n",
        "            # Construct conditional rates of next states\n",
        "            cond_next_rates = base_rates[next_ind] / (1 - base_rates[prev_ind])\n",
        "            # Sample next state\n",
        "            # np.random.multinomial is faster here than np.random.choice\n",
        "            seq.append(state_dict[next_ind[\n",
        "                np.random.multinomial(1, cond_next_rates).argmax()]])\n",
        "    return seq\n",
        "\n",
        "\n",
        "def get_counts(seq, states):\n",
        "    next_count = {a: 0 for a in states}\n",
        "    cond_count = {a: {b: 0 for b in states} for a in states}\n",
        "    num_tr = len(seq) - 1\n",
        "    # Compute next and conditional counts\n",
        "    for i in np.arange(1, len(seq)):\n",
        "        for a in states:\n",
        "            if seq[i - 1] == a:\n",
        "                for b in states:\n",
        "                    if seq[i] == b:\n",
        "                        cond_count[a][b] += 1\n",
        "                        next_count[b] += 1\n",
        "                        break\n",
        "                break\n",
        "\n",
        "    cond_count_list = []\n",
        "    for a in cond_count:\n",
        "        cond_count_list.extend(list(cond_count[a].values()))\n",
        "\n",
        "    return list(next_count.values()), cond_count_list\n",
        "\n",
        "\n",
        "def get_affect_behaviors_counts(seq, states):\n",
        "    next_count = {a: 0 for a in states}\n",
        "    cond_count = {a: {b: 0 for b in states} for a in states}\n",
        "    num_tr = len(seq) - 1\n",
        "    # Compute next and conditional counts\n",
        "    for i in np.arange(1, len(seq)):\n",
        "        for a in states:\n",
        "            if seq[i - 1][0] == a:\n",
        "                for b in states:\n",
        "                    if seq[i][1] == b:\n",
        "                        cond_count[a][b] += 1\n",
        "                        next_count[b] += 1\n",
        "                        break\n",
        "            if seq[i - 1][1] == a:\n",
        "                for b in states:\n",
        "                    if seq[i][0] == b:\n",
        "                        cond_count[a][b] += 1\n",
        "                        next_count[b] += 1\n",
        "                        break\n",
        "            \n",
        "\n",
        "    cond_count_list = []\n",
        "    for a in cond_count:\n",
        "        cond_count_list.extend(list(cond_count[a].values()))\n",
        "\n",
        "    return list(next_count.values()), cond_count_list\n",
        "\n",
        "def get_affect_behaviors_cooccurence_counts(seq, states):\n",
        "    next_count = {a: 0 for a in states}\n",
        "    cond_count = {a: {b: 0 for b in states} for a in states}\n",
        "    num_tr = len(seq) - 1\n",
        "    # Compute next and conditional counts\n",
        "    for i in np.arange(0, len(seq)):\n",
        "        for a in states:\n",
        "            # ['ENG', 'ON_TASK'], ['CON', 'ON_TASK'] \n",
        "            if seq[i][1] == a:\n",
        "                for b in states:\n",
        "                    if seq[i][0] == b:\n",
        "                        cond_count[a][b] += 1\n",
        "                        next_count[a] += 1\n",
        "            \n",
        "    cond_count_list = []\n",
        "    for a in cond_count:\n",
        "        cond_count_list.extend(list(cond_count[a].values()))\n",
        "\n",
        "    return list(next_count.values()), cond_count_list\n",
        "\n",
        "\n",
        "def get_timed_counts(original_seq, timed_seq, states):\n",
        "    next_count = {a: 0 for a in states}\n",
        "    cond_count = {a: {b: 0 for b in states} for a in states}\n",
        "    # num_tr = len(original_seq) - 1\n",
        "    # Compute next counts\n",
        "    for i in np.arange(1, len(original_seq)):\n",
        "        for a in states:\n",
        "            if original_seq[i - 1] == a:\n",
        "                for b in states:\n",
        "                    if original_seq[i] == b:\n",
        "                        next_count[b] += 1\n",
        "                        break\n",
        "                break\n",
        "\n",
        "    # Compute conditional counts\n",
        "    for i in np.arange(1, len(timed_seq)):\n",
        "        for a in states:\n",
        "            if timed_seq[i - 1] == a:\n",
        "                for b in states:\n",
        "                    if timed_seq[i] == b:\n",
        "                        cond_count[a][b] += 1\n",
        "                        break\n",
        "                break\n",
        "\n",
        "    cond_count_list = []\n",
        "    for a in cond_count:\n",
        "        cond_count_list.extend(list(cond_count[a].values()))\n",
        "\n",
        "    return list(next_count.values()), cond_count_list\n",
        "\n",
        "\n",
        "def get_L_star_vals(a, b, next_counts, cond_counts, use_mean_rates=True):\n",
        "    num_states = next_counts.shape[1]\n",
        "    # Column indices where next != a (i.e., transitions in T_{A_complement})\n",
        "    a_comp_ind = (\n",
        "        np.array([i for i in range(num_states) if i != a])\n",
        "    )\n",
        "    # Count transitions where prev == a and next != a\n",
        "    a_comp_cond_sum = cond_counts[:, a_comp_ind + a*num_states].sum(axis=1)\n",
        "    if use_mean_rates:      \n",
        "        # Compute L_star using base rates averaged over the whole sample\n",
        "        # of sequences; note that as opposed to the computation of\n",
        "        # L_star below, we only exclude samples with P(b|a) == nan; that is,\n",
        "        # we only exclude sequences with no transitions from a to another state\n",
        "        sample_pos = np.flatnonzero(\n",
        "            a_comp_cond_sum > 0\n",
        "        )\n",
        "        # Compute mean base rate of b restricted to transitions with next != a\n",
        "        modified_mean_base_rate = np.mean(\n",
        "            next_counts[sample_pos, b] /\n",
        "            next_counts[sample_pos, :][:, a_comp_ind].sum(axis=1)\n",
        "        )\n",
        "        # Compute conditional rate of b restricted to transitions with next != a\n",
        "        cond_rates = (\n",
        "            cond_counts[sample_pos, a*num_states + b] /\n",
        "            a_comp_cond_sum[sample_pos]\n",
        "        )\n",
        "        L_star_vals = (\n",
        "            (cond_rates - modified_mean_base_rate)\n",
        "            / (1 - modified_mean_base_rate)\n",
        "        )\n",
        "    else:\n",
        "        # Compute L_star using base rates from each individual sequence\n",
        "\n",
        "        # Column indices where next != a and next != b\n",
        "        a_b_comp_ind = (\n",
        "            np.array([i for i in range(num_states) if i != a and i != b])\n",
        "        )\n",
        "        # Count transitions where next != a or next != b\n",
        "        a_b_comp_sum = next_counts[:, a_b_comp_ind].sum(axis=1)\n",
        "        # Count transitions where next != a        \n",
        "        a_comp_sum = next_counts[:, b] + a_b_comp_sum\n",
        "        # Find samples where:\n",
        "        #  (a) P(b|a) != nan\n",
        "        #  (b) P(b) < 1\n",
        "        sample_pos = np.flatnonzero(\n",
        "            (a_comp_cond_sum > 0) & (a_b_comp_sum > 0)            \n",
        "        )        \n",
        "        # Compute base rates of b restricted to transitions with next != a\n",
        "        modified_base = (\n",
        "            next_counts[sample_pos, b] / a_comp_sum[sample_pos]\n",
        "        )\n",
        "        # Compute conditional rate of b restricted to transitions with next != a\n",
        "        cond_rates = (\n",
        "            cond_counts[sample_pos, a*num_states + b] /\n",
        "            a_comp_cond_sum[sample_pos]\n",
        "        )       \n",
        "        L_star_vals = (\n",
        "            (cond_rates - modified_base)\n",
        "            / (1 - modified_base)\n",
        "        )\n",
        "    return L_star_vals\n",
        "\n",
        "def get_L_vals(a, b, next_counts, cond_counts, use_mean_rates=True):\n",
        "    num_states = next_counts.shape[1]\n",
        "    # Count transitions where prev == a and next != a\n",
        "    a_cond_sum = cond_counts[\n",
        "        :, np.arange(num_states) + a*num_states].sum(axis=1)\n",
        "    if use_mean_rates:      \n",
        "        # Compute L using base rates averaged over the whole sample\n",
        "        # of sequences.  Note that as opposed to the computation of\n",
        "        # L below, we only exclude samples with P(b|a) == nan; that is,\n",
        "        # we only exclude sequences with no transitions from a \n",
        "        sample_pos = np.flatnonzero(\n",
        "            a_cond_sum > 0\n",
        "        )\n",
        "        # Compute mean base rate of b \n",
        "        mean_base_rate = np.mean(\n",
        "            next_counts[sample_pos, b] /\n",
        "            next_counts[sample_pos, :].sum(axis=1)\n",
        "        )\n",
        "        # Compute conditional rate of b \n",
        "        cond_rates = (\n",
        "            cond_counts[sample_pos, a*num_states + b] /\n",
        "            a_cond_sum[sample_pos]\n",
        "        )\n",
        "        L_vals = (\n",
        "            (cond_rates - mean_base_rate)\n",
        "            / (1 - mean_base_rate)\n",
        "        )\n",
        "    else:\n",
        "        # Compute L using base rates from each individual sequence\n",
        "\n",
        "        # Column indices where next != a and next != b\n",
        "        b_comp_ind = (\n",
        "            np.array([i for i in range(num_states) if i != b])\n",
        "        )\n",
        "        # Count transitions where next != b\n",
        "        b_comp_sum = next_counts[:, b_comp_ind].sum(axis=1)\n",
        "        # Find samples where:\n",
        "        #  (a) P(b|a) != nan\n",
        "        #  (b) P(b) < 1\n",
        "        sample_pos = np.flatnonzero(\n",
        "            (a_cond_sum > 0) & (b_comp_sum > 0)            \n",
        "        )        \n",
        "        # Compute base rates of b\n",
        "        base_rates = (\n",
        "            next_counts[sample_pos, b] / next_counts[sample_pos, :].sum(axis=1)\n",
        "        )\n",
        "        # Compute conditional rate of b\n",
        "        cond_rates = (\n",
        "            cond_counts[sample_pos, a*num_states + b] /\n",
        "            a_cond_sum[sample_pos]\n",
        "        )       \n",
        "        L_vals = (\n",
        "            (cond_rates - base_rates)\n",
        "            / (1 - base_rates)\n",
        "        )\n",
        "    return L_vals\n",
        "\n",
        "\n",
        "def compile_timed_sequence_counts(seq_list, timed_seq_list, states):\n",
        "    next_counts = []\n",
        "    cond_counts = []    \n",
        "    for seq_index in range(len(seq_list)):\n",
        "        # count_res = get_counts(seq, states)\n",
        "        # count_res = get_timed_counts(seq_list[seq_index], timed_seq_list[seq_index], states)\n",
        "        count_res = get_affect_behaviors_counts(seq_list[seq_index], states)\n",
        "        next_counts.append(count_res[0])\n",
        "        cond_counts.append(count_res[1])\n",
        "    return np.array(next_counts), np.array(cond_counts)\n",
        "\n",
        "def compile_sequence_counts(seq_list, states, consider_affect_behaviors_cooccurence=False):\n",
        "    next_counts = []\n",
        "    cond_counts = []    \n",
        "    for seq_index in range(len(seq_list)):\n",
        "        # count_res = get_counts(seq, states)\n",
        "        if consider_affect_behaviors_cooccurence:\n",
        "          count_res = get_affect_behaviors_cooccurence_counts(seq_list[seq_index], states)\n",
        "          # print(\"consider_affect_behaviors_cooccurence\", count_res)\n",
        "        else:\n",
        "          count_res = get_affect_behaviors_counts(seq_list[seq_index], states)\n",
        "          \n",
        "        next_counts.append(count_res[0])\n",
        "        cond_counts.append(count_res[1])\n",
        "    return np.array(next_counts), np.array(cond_counts)\n",
        "\n",
        "\n",
        "def print_vals(val_array, state_dict, title):\n",
        "    print('\\n\\n' + title + '\\n')\n",
        "    print('Prev\\\\Next' + '\\t' + '\\t'.join(map(str, list(state_dict.values()))))\n",
        "    for i in range(len(state_dict)):\n",
        "        print(state_dict[i] + '\\t\\t'\n",
        "              + '\\t'.join(map(str, val_array[i, :].round(4))))\n",
        "    return\n",
        "\n",
        "\n",
        "def run_simulations(\n",
        "        num_trials=50000,\n",
        "        seq_length=21,\n",
        "        states=['A', 'B', 'C', 'D'],\n",
        "        base_rates=np.array([0.45, 0.45, 0.05, 0.05]),\n",
        "        verbose=True,\n",
        "        include_self_transitions=True,\n",
        "        compute_L=True\n",
        "):\n",
        "    num_states = len(states)\n",
        "    state_dict = {}\n",
        "    for i in range(num_states):\n",
        "        state_dict[i] = states[i]\n",
        "    seq_list = []\n",
        "    reduced_seq_list = []\n",
        "    for i in range(num_trials):\n",
        "        seq = generate_sequence(seq_length, state_dict, base_rates,\n",
        "                    include_self_transitions=include_self_transitions)        \n",
        "        reduced_seq = remove_self_transitions(seq)\n",
        "\n",
        "        seq_list.append(seq)\n",
        "        reduced_seq_list.append(reduced_seq)\n",
        "\n",
        "    res = []\n",
        "    # Compute L_star using individual base rates from full sequences with\n",
        "    # self-transitions included     \n",
        "    res.append(\n",
        "        compute_statistic(seq_list, states, L_star=True,\n",
        "                          use_mean_rates=False)\n",
        "    )\n",
        "    # Compute L_star using mean base rates from full sequences with\n",
        "    # self-transitions included         \n",
        "    res.append(\n",
        "        compute_statistic(seq_list, states, L_star=True,\n",
        "                          use_mean_rates=True)\n",
        "    )\n",
        "    if compute_L:\n",
        "        # Compute L using individual base rates from reduced sequences with\n",
        "        # self-transitions removed             \n",
        "        res.append(\n",
        "            compute_statistic(seq_list, states, L_star=False,\n",
        "                              use_mean_rates=False)\n",
        "        )\n",
        "        # Compute L_star using mean base rates from full sequences with\n",
        "        # self-transitions included                  \n",
        "        res.append(\n",
        "            compute_statistic(seq_list, states, L_star=False,\n",
        "                              use_mean_rates=True)\n",
        "        )            \n",
        "\n",
        "    \n",
        "    if verbose:\n",
        "        title_list = [\n",
        "            'L_star with individual base rates from full sequences',\n",
        "            'L_star with mean base rates from full sequences',\n",
        "            'L with individual base rates from reduced sequences',\n",
        "            'L with mean base rates from reduced sequences',\n",
        "        ]\n",
        "        end_ind = 2\n",
        "        if compute_L:\n",
        "            end_ind = len(title_list)\n",
        "        for i in range(end_ind):\n",
        "            print_vals(res[i], state_dict, title_list[i])\n",
        "            \n",
        "    return (\n",
        "        seq_list,\n",
        "        reduced_seq_list,\n",
        "        res\n",
        "    )\n",
        "\n",
        "\n",
        "def compute_statistic(seq_list, states, L_star=True,\n",
        "                      use_mean_rates=True, consider_affect_behaviors_cooccurence=False):\n",
        "    \"\"\" General function for computing L_star and L statistics\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    seq_list : list of lists\n",
        "        Each entry in the list is a sequence (list) of affective states; note \n",
        "        that self-transitions are automatically removed if L_star is false\n",
        "        Example:\n",
        "            [\n",
        "                ['A', 'C', 'C', 'B', 'C'],\n",
        "                ['B', 'C', 'A', 'C'],\n",
        "                ['C', 'C', 'C', 'B', 'B', 'A']\n",
        "            ]\n",
        "    states : list \n",
        "        List containing all possible affective states \n",
        "        Example:\n",
        "            ['A', 'B', 'C']\n",
        "    L_star : bool, default=True \n",
        "        If true compute L_star statistic; otherwise, remove \n",
        "        self-transitions and compute L statistic\n",
        "    use_mean_rates : bool, default=True\n",
        "        If true compute base rates averaged over all sequences; otherwise,\n",
        "       compute base rates individually per sequence\n",
        "    \"\"\"\n",
        "    \n",
        "    if L_star:\n",
        "        input_list = seq_list\n",
        "    else:\n",
        "        input_list = []\n",
        "        for i in range(len(seq_list)):\n",
        "            input_list.append(remove_behavior_self_transitions(seq_list[i]))\n",
        "        \n",
        "    next_counts, cond_counts = compile_sequence_counts(input_list, states, consider_affect_behaviors_cooccurence)\n",
        "\n",
        "    # print(\"next_counts\", next_counts)\n",
        "    # print(\"cond_counts\", cond_counts)\n",
        "\n",
        "    num_states = len(states)\n",
        "    res = np.full((num_states, num_states), np.nan)\n",
        "    test = np.full((num_states, num_states), object)\n",
        "    for i in range(num_states):\n",
        "        for j in range(num_states):\n",
        "            if i != j:\n",
        "                if L_star:\n",
        "                    aux = get_L_star_vals(i, j, next_counts, cond_counts, use_mean_rates=use_mean_rates)\n",
        "\n",
        "                    res[i, j] = np.mean(aux)\n",
        "                    test[i, j] = aux\n",
        "                else:\n",
        "                    aux = get_L_vals(i, j, next_counts, cond_counts, use_mean_rates=use_mean_rates)\n",
        "                    \n",
        "                    res[i, j] = np.mean(aux)\n",
        "                    test[i, j] = aux\n",
        "\n",
        "    return res, test\n",
        "\n",
        "\n",
        "def base_rate_analysis(\n",
        "        states=['A', 'B', 'C', 'D'],\n",
        "        base_rates=np.ones(4)*0.25,\n",
        "        num_steps=24,\n",
        "        rate_step=[0.03, -0.01, -0.01, -0.01],\n",
        "        num_trials=50000,\n",
        "        seq_length=21\n",
        "):\n",
        "    \"\"\" Run numerical experiments \n",
        "    \n",
        "    Experiment 1 parameters: \n",
        "        states=['A', 'B', 'C', 'D'], \n",
        "        base_rates=np.ones(4)*0.25, \n",
        "        num_steps=24, \n",
        "        rate_step=[0.03, -0.01, -0.01, -0.01],\n",
        "        num_trials=50000,\n",
        "        seq_length=21\n",
        "\n",
        "    Experiment 2 parameters: \n",
        "        states=['A', 'B', 'C', 'D'], \n",
        "        base_rates=np.ones(4)*0.25, \n",
        "        num_steps=23, \n",
        "        rate_step=[0.01, 0.01, -0.01, -0.01],\n",
        "        num_trials=50000,\n",
        "        seq_length=21\n",
        "    \n",
        "    \"\"\"\n",
        "    rate_step = np.array(rate_step)\n",
        "    indiv_rate_results = []\n",
        "    mean_rate_results = []\n",
        "    all_base_rates = []\n",
        "    for i in range(num_steps):\n",
        "        sim_res = run_simulations(\n",
        "            num_trials=num_trials,\n",
        "            seq_length=seq_length,\n",
        "            states=states,\n",
        "            base_rates=base_rates,\n",
        "            verbose=False,\n",
        "            include_self_transitions=True,\n",
        "            compute_L=False\n",
        "        )\n",
        "        indiv_rate_results.append(sim_res[2][0])\n",
        "        mean_rate_results.append(sim_res[2][1])\n",
        "        all_base_rates.append(list(base_rates))\n",
        "        if i < num_steps - 1:\n",
        "            base_rates += rate_step\n",
        "    return indiv_rate_results, mean_rate_results, all_base_rates\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Execution 3: Definition of the functions and statistical calculations\n",
        "---\n",
        "This part of the code is the definition of the auxiliary functions for the calculation of the L metric, the p-value statistics and multiple tests and for the printing part of the results and the affect dynamics graph.\n"
      ],
      "metadata": {
        "id": "5LQfg5T3VAZI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvOmuuPHg9Mw"
      },
      "source": [
        "# Function that computes the list of students that should be included in the analysis of the dynamics of emotions\n",
        "# Returns a list with the ids of the students that will be included\n",
        "# Output example: [1, 2, 3, 4, 5]\n",
        "\n",
        "# students_amount -> the number of students that should be considered\n",
        "#   by default this value is 30, but any value can be passed by parameter\n",
        "\n",
        "# gender_filter -> specify whether the students should be filtered according their gender\n",
        "#   by default this value is False\n",
        "\n",
        "# gender_text -> specify which gender \"M\" or \"F\" should be used to filter students\n",
        "#   by default this value is \"M\"\n",
        "\n",
        "# show_info -> receives a boolean that informs if it is to display the information of the selected students\n",
        "#   by default this value is True\n",
        "\n",
        "def compute_students_to_include(students_amount=30,\n",
        "                                gender_filter=False,\n",
        "                                gender_text=\"M\",\n",
        "                                show_info=True):\n",
        "\n",
        "  students_to_include = []\n",
        "  for n_student in range(1, students_amount + 1, 1):\n",
        "    include_n_student = False\n",
        "    \n",
        "    # condition to include or not students according their gender\n",
        "    if gender_filter:\n",
        "      if df_students_info[df_students_info.student_id == n_student].gender.values[0] == gender_text:\n",
        "        include_n_student = True\n",
        "      else: \n",
        "        include_n_student = False\n",
        "\n",
        "    if not gender_filter:\n",
        "      include_n_student = True\n",
        "\n",
        "    if include_n_student:\n",
        "      students_to_include.append(n_student)\n",
        "\n",
        "  if show_info:\n",
        "    print(\"Number of students: \", len(students_to_include))\n",
        "    print(\"Students ids: \", students_to_include)\n",
        "  \n",
        "  return students_to_include\n",
        "\n",
        "\n",
        "# receives a list of students ids to be considered and filter the emotion labels based on this list \n",
        "# and filters that can be modified according to the following paramenters\n",
        "\n",
        "# students_to_include -> a list of students id to be considered\n",
        "#   by default this value is []\n",
        "\n",
        "# consider_emotion_duration -> a boolean to define whether the emotion labels dataset with permanence time should be considered\n",
        "#   by default this value is False\n",
        "\n",
        "# consider_emotion_duration -> a boolean to define whether the emotion labels should be filtered by the permanence time\n",
        "#   by default this value is False\n",
        "\n",
        "# emotion_to_filter_text -> the emotion that will be used to filter as the source emotion\n",
        "#   by default this value is \"ENG\"\n",
        "\n",
        "# duration_greater_than -> a boolean to define whether the permanence time in the emotion_to_filter_text should be greater or less then a certain threshold\n",
        "#   by default this value is True\n",
        "\n",
        "# duration_threshold_method -> defines the method to calculate the emotion duration threshold\n",
        "#   by default this value is \"mean\"\n",
        "\n",
        "# show_info -> receives a boolean that informs if it is to display the information of the selected students\n",
        "#   by default this value is True\n",
        "def compute_list_of_emotion_labels(students_to_include=[],\n",
        "                                   consider_emotion_duration=False,\n",
        "                                   filter_emotion_duration=False,\n",
        "                                   emotion_to_filter_text=\"ENG\",\n",
        "                                   duration_greater_than=True,\n",
        "                                   duration_threshold_method=\"mean\",\n",
        "                                   show_info=True):\n",
        "\n",
        "  # it computes the emotion sequences for each student\n",
        "  transitions_list = []\n",
        "  duration_threshold = calculate_emotion_duration_stats(emotion_to_filter_text)[duration_threshold_method]\n",
        "  for n_student in students_to_include:\n",
        "    if consider_emotion_duration:\n",
        "      emotions_duration_labels = df_emotions_duration[df_emotions_duration.student_id == n_student]\n",
        "      if filter_emotion_duration:\n",
        "        if duration_greater_than:\n",
        "          emotions_duration_labels = emotions_duration_labels[((emotions_duration_labels.emotion_label == emotion_to_filter_text) & (emotions_duration_labels.duration >= duration_threshold) | (emotions_duration_labels.emotion_label != emotion_to_filter_text))]\n",
        "        else:\n",
        "          emotions_duration_labels = emotions_duration_labels[((emotions_duration_labels.emotion_label == emotion_to_filter_text) & (emotions_duration_labels.duration <= duration_threshold) | (emotions_duration_labels.emotion_label != emotion_to_filter_text))]\n",
        "\n",
        "      transitions_list.append(list(emotions_duration_labels.emotion_label.values))\n",
        "    else:\n",
        "      # transitions_list.append(list(df_labels[df_labels.student_id == n_student].emotion_label.values))\n",
        "      transitions_list.append(list(df_labels[df_labels.student_id == n_student][[\"emotion_label\", \"behavior_label\"\n",
        "]].apply(lambda x: [x[\"emotion_label\"], x[\"behavior_label\"]], axis=1)))\n",
        "\n",
        "  if show_info:\n",
        "    print(\"Affective states: \", emotions_list)\n",
        "    print(\"Number of transition lists: \", len(transitions_list))\n",
        "    print(\"Labels for each list:\")\n",
        "    for i in range(len(transitions_list)):\n",
        "      print(str(students_to_include[i]) + \": \" + str(len(transitions_list[i])))\n",
        "    if consider_emotion_duration and filter_emotion_duration:\n",
        "      if duration_greater_than:\n",
        "        print(\"Number of resulting transitions: \", len(df_emotions_duration[(df_emotions_duration.emotion_label == emotion_to_filter_text) & (df_emotions_duration.duration >= duration_threshold)]))\n",
        "      else: \n",
        "        print(\"Number of resulting transitions: \", len(df_emotions_duration[(df_emotions_duration.emotion_label == emotion_to_filter_text) & (df_emotions_duration.duration <= duration_threshold)]))\n",
        "\n",
        "  return transitions_list\n",
        "\n",
        "\n",
        "# compute the number of transitions between all the states and students\n",
        "def get_emotion_transitions_counts(list_seq, states):\n",
        "  cond_count = {a: {b: 0 for b in states} for a in states}\n",
        "  for j in np.arange(0, len(list_seq)):\n",
        "    seq = list_seq[j]\n",
        "    num_tr = len(seq) - 1\n",
        "    # Compute next and conditional counts\n",
        "    for i in np.arange(1, len(seq)):\n",
        "      for a in states:\n",
        "          if seq[i - 1][0] == a:\n",
        "              for b in states:\n",
        "                  if seq[i][1] == b:\n",
        "                      cond_count[a][b] += 1\n",
        "                      break\n",
        "          if seq[i - 1][1] == a:\n",
        "              for b in states:\n",
        "                  if seq[i][0] == b:\n",
        "                      cond_count[a][b] += 1\n",
        "                      break\n",
        "\n",
        "  return cond_count\n",
        "\n",
        "\n",
        "def get_emotion_behavior_cooccurence_counts(list_seq, states):\n",
        "  cond_count = {a: {b: 0 for b in states} for a in states}\n",
        "  for j in np.arange(0, len(list_seq)):\n",
        "    seq = list_seq[j]\n",
        "    num_tr = len(seq) - 1\n",
        "    # Compute next and conditional counts\n",
        "    for i in np.arange(1, len(seq)):\n",
        "      for a in states:\n",
        "          if seq[i - 1][1] == a:\n",
        "              for b in states:\n",
        "                  if seq[i - 1][0] == b:\n",
        "                      cond_count[a][b] += 1\n",
        "                      break\n",
        "\n",
        "  return cond_count\n",
        "\n",
        "\n",
        "# compute and return the statistics about the permanence time of an emotion entered as text\n",
        "def calculate_emotion_duration_stats(emotion_text):\n",
        "  emotion_duration_stats = {}\n",
        "  emotion_duration_stats[\"min\"] = df_emotions_duration.loc[df_emotions_duration.emotion_label == emotion_text].duration.min()\n",
        "  emotion_duration_stats[\"max\"] = df_emotions_duration.loc[df_emotions_duration.emotion_label == emotion_text].duration.max()\n",
        "  emotion_duration_stats[\"mean\"] = df_emotions_duration.loc[df_emotions_duration.emotion_label == emotion_text].duration.mean()\n",
        "  emotion_duration_stats[\"median\"] = df_emotions_duration.loc[df_emotions_duration.emotion_label == emotion_text].duration.median()\n",
        "  emotion_duration_stats[\"std\"] = df_emotions_duration.loc[df_emotions_duration.emotion_label == emotion_text].duration.std()\n",
        "  emotion_duration_stats[\"shapiro\"], emotion_duration_stats[\"shapiro_p_value\"] = shapiro(df_emotions_duration.loc[df_emotions_duration.emotion_label == emotion_text].duration)\n",
        "  return emotion_duration_stats\n",
        "\n",
        "# print the statistics of an emotion entered as text\n",
        "def print_emotion_duration_stats(emotion_text):\n",
        "  emotion_duration_stats = calculate_emotion_duration_stats(emotion_text)\n",
        "  print(\"-------------- Emotion \", emotion_text, \" ----------------------------\")\n",
        "  print(\"Min: \", emotion_duration_stats[\"min\"])\n",
        "  print(\"Max: \", emotion_duration_stats[\"max\"])\n",
        "  print(\"Mean: \", emotion_duration_stats[\"mean\"])\n",
        "  print(\"Median: \", emotion_duration_stats[\"median\"])\n",
        "  print(\"Std. Dev.: \", emotion_duration_stats[\"std\"])\n",
        "  print('Shapiro-Wilk=%.3f, p=%.3f' % (emotion_duration_stats[\"shapiro\"], emotion_duration_stats[\"shapiro_p_value\"]))\n",
        "\n",
        "# receives a matrix with the L metric average for each emotion transition combination and calculates the p-value for each combination\n",
        "def calculate_p_values(states_list, L_metric_average_results, level_at_change):\n",
        "  num_states = len(states_list)\n",
        "  matrix_p_values = np.full((num_states, num_states), np.nan)\n",
        "  for i in range(num_states):\n",
        "    for j in range(num_states):\n",
        "      if i != j:\n",
        "        matrix_p_values[i][j] = stats.ttest_1samp(list(L_metric_average_results[i][j]), level_at_change).pvalue\n",
        "  return matrix_p_values\n",
        "\n",
        "# calculate Benjamini/Hochberg multiple test adjustment for the p-values matrix\n",
        "# https://www.statsmodels.org/dev/generated/statsmodels.stats.multitest.multipletests.html\n",
        "def calculate_multiple_t_test_adjustment(states_list, matrix_p_values):\n",
        "  num_states = len(states_list)\n",
        "  multiple_tests_matrix = np.full((num_states ,num_states), np.nan)\n",
        "  multiple_tests_reject_matrix = np.full((num_states ,num_states), np.nan)\n",
        "\n",
        "  for i in range(num_states):\n",
        "    pvals =[x for x in matrix_p_values[i] if str(x) != 'nan']\n",
        "    if len(pvals) > 0:\n",
        "      line_bh = multi.multipletests(pvals, alpha=0.05, method='fdr_bh', is_sorted=False, returnsorted=False)\n",
        "      for j in range(num_states - 1):\n",
        "        column = j\n",
        "        if j >= i:\n",
        "          column = column + 1\n",
        "        multiple_tests_matrix[i][column] = line_bh[1][j]\n",
        "        multiple_tests_reject_matrix[i][column] = line_bh[0][j]\n",
        "  \n",
        "  return multiple_tests_matrix, multiple_tests_reject_matrix\n",
        "\n",
        "\n",
        "# print the table with information about the all the emotion's transitions allowing to select which information is going to be printed\n",
        "def print_vals(l_matrix, p_value_matrix, multiple_tests_matrix, multiple_tests_reject_matrix, count_matrix, states_list, print_types, lines_to_include=[0, 1, 2, 3, 4], columns_to_include=[0, 1, 2, 3, 4]):\n",
        "  \n",
        "  labels_to_print = \";\".join(label for (index, label) in enumerate(states_list) if index in columns_to_include)\n",
        "  print('Prev\\\\Next;' + labels_to_print)\n",
        "  for i in range(len(states_list)):\n",
        "    if i in lines_to_include:\n",
        "      print(states_list[i] + ';', end =\"\")\n",
        "      for j in range(len(states_list)):\n",
        "        if j in columns_to_include:\n",
        "          if \"L_metric\" in print_types:\n",
        "            print('na' if np.isnan(l_matrix[i,j]) else format((l_matrix[i,j]).round(4), '.4f'), end=\"\", flush=True)\n",
        "          if \"p_value\" in print_types:\n",
        "            print(' (', end=\"\", flush=True) if len(print_types) > 1 else False\n",
        "            print('na' if np.isnan(p_value_matrix[i,j]) else format((p_value_matrix[i,j]).round(4), '.4f'), end=\"\", flush=True)\n",
        "            print(') ', end=\"\", flush=True) if len(print_types) > 1 else False\n",
        "          if \"multiple_test_p_value\" in print_types:\n",
        "            print(' |', end=\"\", flush=True) if len(print_types) > 1 else False\n",
        "            print('na' if np.isnan(multiple_tests_matrix[i,j]) else format((multiple_tests_matrix[i,j]).round(4), '.4f'), end=\"\", flush=True)\n",
        "            print('| ', end=\"\", flush=True) if len(print_types) > 1 else False\n",
        "          if \"transition_count\" in print_types:\n",
        "            print(' [', end=\"\", flush=True) if len(print_types) > 1 else False\n",
        "            print('na' if np.isnan(count_matrix[states_list[i]][states_list[j]]) else str((count_matrix[states_list[i]][states_list[j]])), end=\"\", flush=True) \n",
        "            print('] ', end=\"\", flush=True) if len(print_types) > 1 else False\n",
        "          if \"multiple_test_significance\" in print_types:\n",
        "            print(' {', end=\"\", flush=True) if len(print_types) > 1 else False\n",
        "            print('na' if np.isnan(multiple_tests_reject_matrix[i,j]) else format((multiple_tests_reject_matrix[i,j]).round(4), '.1f'), end=\"\", flush=True)\n",
        "            print('} ', end=\"\", flush=True) if len(print_types) > 1 else False\n",
        "          \n",
        "          if j < len(states_list) - 1:\n",
        "            print(';', end=\"\", flush=True)\n",
        "      print(\"\")\n",
        "  return\n",
        "\n",
        "# print the affect dynamics graph based on the L matrix and the multiple tests adjustment rejection status\n",
        "def print_affect_dynamics_graph(l_matrix, multiple_tests_reject_matrix, states_list, threshold):\n",
        "  fig, ax = plt.subplots(figsize=(10,10))\n",
        "\n",
        "  G = nx.MultiDiGraph()  # Create empty graph\n",
        "\n",
        "  # create the nodes based on the states list\n",
        "  G.add_nodes_from(states_list)\n",
        "\n",
        "  for i in range(len(states_list)):\n",
        "    for j in range(len(states_list)):\n",
        "      is_significant = (np.zeros(1)[0] if np.isnan(multiple_tests_reject_matrix[i,j]) else multiple_tests_reject_matrix[i,j]).round(1)\n",
        "      if i != j and is_significant > 0:\n",
        "        transition_l = (np.zeros(1)[0] if np.isnan(l_matrix[i,j]) else l_matrix[i,j]).round(2)\n",
        "        transition_color = 'red' if transition_l < threshold else 'blue'\n",
        "        # add the edges with the l_metric as weight only if the transition is significant (based on the multiple test adjustment)\n",
        "        # change the color for red if the transition is unlikely and blue if it is more likely to occur\n",
        "        G.add_edge(states_list[i], states_list[j], color=transition_color, weight=format(transition_l, '.2f'))\n",
        "  \n",
        "  pos =  nx.circular_layout(G, scale=1)  # List of positions of nodes\n",
        "\n",
        "  colors = []\n",
        "\n",
        "  for (u,v,attrib_dict) in list(G.edges.data()):\n",
        "      colors.append(attrib_dict['color'])\n",
        "\n",
        "  weights = [(0.4 + abs(float(d['weight'])) + abs(float(d['weight'])) * 4) for u,v,d in G.edges(data=True)]\n",
        "  nx.draw(G, pos, with_labels=True, connectionstyle='arc3, rad = 0.15', node_size=1200, edge_color=colors, width=weights, node_color='lightgreen')\n",
        "  edge_labels = dict([((u,v,),d['weight']) for u,v,d in G.edges(data=True)])\n",
        "\n",
        "  nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, label_pos=0.2, font_size=11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Execution 4: Dynamics between affect and behaviors\n",
        "---\n",
        "This part of the code executes the previous defined functions and set the paremeters to calculate dynamics between affect and behaviors, considering the data from all the students.\n"
      ],
      "metadata": {
        "id": "5wPWz725iUFJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oipz1B7B1sTU",
        "outputId": "a7075ffa-f58d-49a9-bce8-0a611d5aaf1d"
      },
      "source": [
        "print(\"The probability of an affect to onset a behavior - all students\")\n",
        "\n",
        "# it computes the list of students to be included in the analysis \n",
        "students_to_include_list = compute_students_to_include( students_amount=30,\n",
        "                                                        gender_filter=False,\n",
        "                                                        gender_text=\"M\",\n",
        "                                                        show_info=True)\n",
        "\n",
        "# it computes the list of emotions labels to be considered according to the list of students\n",
        "transitions_list = compute_list_of_emotion_labels(students_to_include=students_to_include_list,\n",
        "                                                  consider_emotion_duration=False,\n",
        "                                                  filter_emotion_duration=False,\n",
        "                                                  emotion_to_filter_text=\"ENG\",\n",
        "                                                  duration_greater_than=True,\n",
        "                                                  duration_threshold_method=\"mean\",\n",
        "                                                  show_info=False)\n",
        "\n",
        "# based on the list of emotions labels, it computes the L metric matrix and the averaged L matrix\n",
        "L_metric_results, L_metric_average_results = compute_statistic(seq_list=transitions_list,\n",
        "                                                               states=emotions_behaviors_list, \n",
        "                                                               L_star=False, \n",
        "                                                               use_mean_rates=False)\n",
        "\n",
        "# compute the p values for each transition according to the L matrix and the average L matrix\n",
        "p_values_matrix = calculate_p_values(states_list=emotions_behaviors_list, \n",
        "                                     L_metric_average_results=L_metric_average_results, \n",
        "                                     level_at_change=L_metric_at_chance_threshold)\n",
        "\n",
        "# compute the t test adjustment according to the BH post hoc method \n",
        "multiple_tests_matrix, multiple_tests_reject_matrix = calculate_multiple_t_test_adjustment(states_list=emotions_behaviors_list, \n",
        "                                                                                           matrix_p_values=p_values_matrix)\n",
        "\n",
        "# compute the emotion transitions count\n",
        "emotion_counts = get_emotion_transitions_counts(list_seq=transitions_list, \n",
        "                                                states=emotions_behaviors_list)\n",
        "\n",
        "\n",
        "# print the results according to the predefined metrics\n",
        "print_vals(L_metric_results, \n",
        "           p_values_matrix, \n",
        "           multiple_tests_matrix, \n",
        "           multiple_tests_reject_matrix, \n",
        "           emotion_counts, \n",
        "           emotions_behaviors_list,\n",
        "           print_types=table_metrics_to_print,\n",
        "           lines_to_include=[0, 1, 2, 3, 4],\n",
        "           columns_to_include=[5, 6, 7, 8, 9])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The probability of an affect to onset a behavior - all students\n",
            "Number of students:  30\n",
            "Students ids:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
            "Prev\\Next;ON_TASK;ON_SYSTEM;ON_TASK_RES;OFF_TASK;ON_TASK_CONV\n",
            "ENG;0.2614 (0.0000)  [2150]  {1.0} ;0.1479 (0.0008)  [169]  {1.0} ;0.0437 (0.1142)  [319]  {0.0} ;0.1212 (0.0318)  [121]  {1.0} ;0.0343 (0.0446)  [92]  {0.0} \n",
            "CON;0.4013 (0.0000)  [643]  {1.0} ;-0.0208 (0.0012)  [160]  {1.0} ;0.0421 (0.3274)  [45]  {0.0} ;0.0981 (0.3873)  [52]  {0.0} ;0.1364 (0.1208)  [281]  {0.0} \n",
            "FRU;0.4691 (0.0067)  [60]  {1.0} ;-0.0170 (0.0126)  [88]  {1.0} ;0.0329 (0.6783)  [1]  {0.0} ;0.0245 (0.4464)  [13]  {0.0} ;0.1329 (0.3421)  [15]  {0.0} \n",
            "BOR;0.6077 (0.0000)  [108]  {1.0} ;0.0403 (0.6986)  [115]  {0.0} ;0.0331 (0.5180)  [2]  {0.0} ;0.0557 (0.9000)  [45]  {0.0} ;-0.0414 (0.0000)  [0]  {1.0} \n",
            "OTH;0.5788 (0.0000)  [175]  {1.0} ;0.0543 (0.7361)  [372]  {0.0} ;0.0128 (0.0045)  [12]  {1.0} ;0.0287 (0.2648)  [425]  {0.0} ;0.0128 (0.0015)  [25]  {1.0} \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The probability of an affect to onset a behavior - female students\")\n",
        "\n",
        "# it computes the list of students to be included in the analysis \n",
        "students_to_include_list = compute_students_to_include( students_amount=30,\n",
        "                                                        gender_filter=True,\n",
        "                                                        gender_text=\"F\",\n",
        "                                                        show_info=True)\n",
        "\n",
        "# it computes the list of emotions labels to be considered according to the list of students\n",
        "transitions_list = compute_list_of_emotion_labels(students_to_include=students_to_include_list,\n",
        "                                                  consider_emotion_duration=False,\n",
        "                                                  filter_emotion_duration=False,\n",
        "                                                  emotion_to_filter_text=\"ENG\",\n",
        "                                                  duration_greater_than=True,\n",
        "                                                  duration_threshold_method=\"mean\",\n",
        "                                                  show_info=False)\n",
        "\n",
        "# based on the list of emotions labels, it computes the L metric matrix and the averaged L matrix\n",
        "L_metric_results, L_metric_average_results = compute_statistic(seq_list=transitions_list,\n",
        "                                                               states=emotions_behaviors_list, \n",
        "                                                               L_star=False, \n",
        "                                                               use_mean_rates=False)\n",
        "\n",
        "# compute the p values for each transition according to the L matrix and the average L matrix\n",
        "p_values_matrix = calculate_p_values(states_list=emotions_behaviors_list, \n",
        "                                     L_metric_average_results=L_metric_average_results, \n",
        "                                     level_at_change=L_metric_at_chance_threshold)\n",
        "\n",
        "# compute the t test adjustment according to the BH post hoc method \n",
        "multiple_tests_matrix, multiple_tests_reject_matrix = calculate_multiple_t_test_adjustment(states_list=emotions_behaviors_list, \n",
        "                                                                                           matrix_p_values=p_values_matrix)\n",
        "\n",
        "# compute the emotion transitions count\n",
        "emotion_counts = get_emotion_transitions_counts(list_seq=transitions_list, \n",
        "                                                states=emotions_behaviors_list)\n",
        "\n",
        "\n",
        "# print the results according to the predefined metrics\n",
        "print_vals(L_metric_results, \n",
        "           p_values_matrix, \n",
        "           multiple_tests_matrix, \n",
        "           multiple_tests_reject_matrix, \n",
        "           emotion_counts, \n",
        "           emotions_behaviors_list,\n",
        "           print_types=table_metrics_to_print,\n",
        "           lines_to_include=[0, 1, 2, 3, 4],\n",
        "           columns_to_include=[5, 6, 7, 8, 9])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teZ8Pjed5wCr",
        "outputId": "27961877-43f2-4517-c2b4-3fba9a4aeb9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The probability of an affect to onset a behavior - female students\n",
            "Number of students:  16\n",
            "Students ids:  [1, 2, 6, 9, 11, 13, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27]\n",
            "Prev\\Next;ON_TASK;ON_SYSTEM;ON_TASK_RES;OFF_TASK;ON_TASK_CONV\n",
            "ENG;0.2557 (0.0001)  [1214]  {1.0} ;0.1259 (0.0499)  [62]  {0.0} ;0.0553 (0.6759)  [161]  {0.0} ;0.1237 (0.0720)  [72]  {0.0} ;0.0439 (0.4171)  [38]  {0.0} \n",
            "CON;0.4281 (0.0007)  [262]  {1.0} ;0.0116 (0.1324)  [144]  {0.0} ;0.0133 (0.0288)  [22]  {1.0} ;0.0907 (0.4879)  [42]  {0.0} ;0.1140 (0.4418)  [158]  {0.0} \n",
            "FRU;0.2987 (0.2193)  [28]  {0.0} ;-0.0285 (0.0763)  [86]  {0.0} ;0.1098 (0.7621)  [1]  {0.0} ;0.0349 (0.7297)  [8]  {0.0} ;0.2086 (0.2254)  [8]  {0.0} \n",
            "BOR;0.6031 (0.0004)  [55]  {1.0} ;0.0236 (0.4901)  [93]  {0.0} ;0.0687 (0.9342)  [2]  {0.0} ;0.0430 (0.6888)  [27]  {0.0} ;-0.0504 (0.0000)  [0]  {1.0} \n",
            "OTH;0.5579 (0.0001)  [70]  {1.0} ;0.0356 (0.4681)  [201]  {0.0} ;0.0038 (0.0035)  [6]  {1.0} ;0.0658 (0.9480)  [209]  {0.0} ;0.0241 (0.1414)  [22]  {0.0} \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The probability of an affect to onset a behavior - male students\")\n",
        "\n",
        "# it computes the list of students to be included in the analysis \n",
        "students_to_include_list = compute_students_to_include( students_amount=30,\n",
        "                                                        gender_filter=True,\n",
        "                                                        gender_text=\"M\",\n",
        "                                                        show_info=True)\n",
        "\n",
        "# it computes the list of emotions labels to be considered according to the list of students\n",
        "transitions_list = compute_list_of_emotion_labels(students_to_include=students_to_include_list,\n",
        "                                                  consider_emotion_duration=False,\n",
        "                                                  filter_emotion_duration=False,\n",
        "                                                  emotion_to_filter_text=\"ENG\",\n",
        "                                                  duration_greater_than=True,\n",
        "                                                  duration_threshold_method=\"mean\",\n",
        "                                                  show_info=False)\n",
        "\n",
        "# based on the list of emotions labels, it computes the L metric matrix and the averaged L matrix\n",
        "L_metric_results, L_metric_average_results = compute_statistic(seq_list=transitions_list,\n",
        "                                                               states=emotions_behaviors_list, \n",
        "                                                               L_star=False, \n",
        "                                                               use_mean_rates=False)\n",
        "\n",
        "# compute the p values for each transition according to the L matrix and the average L matrix\n",
        "p_values_matrix = calculate_p_values(states_list=emotions_behaviors_list, \n",
        "                                     L_metric_average_results=L_metric_average_results, \n",
        "                                     level_at_change=L_metric_at_chance_threshold)\n",
        "\n",
        "# compute the t test adjustment according to the BH post hoc method \n",
        "multiple_tests_matrix, multiple_tests_reject_matrix = calculate_multiple_t_test_adjustment(states_list=emotions_behaviors_list, \n",
        "                                                                                           matrix_p_values=p_values_matrix)\n",
        "\n",
        "# compute the emotion transitions count\n",
        "emotion_counts = get_emotion_transitions_counts(list_seq=transitions_list, \n",
        "                                                states=emotions_behaviors_list)\n",
        "\n",
        "\n",
        "# print the results according to the predefined metrics\n",
        "print_vals(L_metric_results, \n",
        "           p_values_matrix, \n",
        "           multiple_tests_matrix, \n",
        "           multiple_tests_reject_matrix, \n",
        "           emotion_counts, \n",
        "           emotions_behaviors_list,\n",
        "           print_types=table_metrics_to_print,\n",
        "           lines_to_include=[0, 1, 2, 3, 4],\n",
        "           columns_to_include=[5, 6, 7, 8, 9])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zCRLBxF55Rp",
        "outputId": "1edb32aa-c4ca-479d-9b17-6353bd426e91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The probability of an affect to onset a behavior - male students\n",
            "Number of students:  14\n",
            "Students ids:  [3, 4, 5, 7, 8, 10, 12, 14, 15, 16, 25, 28, 29, 30]\n",
            "Prev\\Next;ON_TASK;ON_SYSTEM;ON_TASK_RES;OFF_TASK;ON_TASK_CONV\n",
            "ENG;0.2679 (0.0003)  [936]  {1.0} ;0.1731 (0.0075)  [107]  {1.0} ;0.0304 (0.0556)  [158]  {0.0} ;0.1182 (0.2250)  [49]  {0.0} ;0.0233 (0.0142)  [54]  {1.0} \n",
            "CON;0.3706 (0.0102)  [381]  {1.0} ;-0.0579 (0.0023)  [16]  {1.0} ;0.0750 (0.7355)  [23]  {0.0} ;0.1065 (0.5723)  [10]  {0.0} ;0.1620 (0.1628)  [123]  {0.0} \n",
            "FRU;0.6183 (0.0174)  [32]  {1.0} ;-0.0070 (0.1171)  [2]  {0.0} ;-0.0344 (0.0004)  [0]  {1.0} ;0.0154 (0.5024)  [5]  {0.0} ;0.0666 (0.9668)  [7]  {0.0} \n",
            "BOR;0.6147 (0.0096)  [53]  {1.0} ;0.0653 (0.9816)  [22]  {0.0} ;-0.0203 (0.0000)  [0]  {1.0} ;0.0749 (0.9174)  [18]  {0.0} ;-0.0280 (0.0002)  [0]  {1.0} \n",
            "OTH;0.6046 (0.0000)  [105]  {1.0} ;0.0773 (0.6410)  [171]  {0.0} ;0.0240 (0.2197)  [6]  {0.0} ;-0.0169 (0.0022)  [216]  {1.0} ;-0.0011 (0.0000)  [3]  {1.0} \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Execution 5: Dynamics between behaviors and affect\n",
        "---\n",
        "This part of the code executes the previous defined functions and set the paremeters to calculate dynamics between behaviors and affect, considering the data from all the students.\n"
      ],
      "metadata": {
        "id": "pRcXOd5Lc6nl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The probability of a behavior to onset an affect - all students\")\n",
        "\n",
        "# it computes the list of students to be included in the analysis \n",
        "students_to_include_list = compute_students_to_include( students_amount=30,\n",
        "                                                        gender_filter=False,\n",
        "                                                        gender_text=\"M\",\n",
        "                                                        show_info=True)\n",
        "\n",
        "# it computes the list of emotions labels to be considered according to the list of students\n",
        "transitions_list = compute_list_of_emotion_labels(students_to_include=students_to_include_list,\n",
        "                                                  consider_emotion_duration=False,\n",
        "                                                  filter_emotion_duration=False,\n",
        "                                                  emotion_to_filter_text=\"ENG\",\n",
        "                                                  duration_greater_than=True,\n",
        "                                                  duration_threshold_method=\"mean\",\n",
        "                                                  show_info=False)\n",
        "\n",
        "# based on the list of emotions labels, it computes the L metric matrix and the averaged L matrix\n",
        "L_metric_results, L_metric_average_results = compute_statistic(seq_list=transitions_list,\n",
        "                                                               states=emotions_behaviors_list, \n",
        "                                                               L_star=False, \n",
        "                                                               use_mean_rates=False)\n",
        "\n",
        "# compute the p values for each transition according to the L matrix and the average L matrix\n",
        "p_values_matrix = calculate_p_values(states_list=emotions_behaviors_list, \n",
        "                                     L_metric_average_results=L_metric_average_results, \n",
        "                                     level_at_change=L_metric_at_chance_threshold)\n",
        "\n",
        "# compute the t test adjustment according to the BH post hoc method \n",
        "multiple_tests_matrix, multiple_tests_reject_matrix = calculate_multiple_t_test_adjustment(states_list=emotions_behaviors_list, \n",
        "                                                                                           matrix_p_values=p_values_matrix)\n",
        "\n",
        "# compute the emotion transitions count\n",
        "emotion_counts = get_emotion_transitions_counts(list_seq=transitions_list, \n",
        "                                                states=emotions_behaviors_list)\n",
        "\n",
        "\n",
        "# print the results according to the predefined metrics\n",
        "print_vals(L_metric_results, \n",
        "           p_values_matrix, \n",
        "           multiple_tests_matrix, \n",
        "           multiple_tests_reject_matrix, \n",
        "           emotion_counts, \n",
        "           emotions_behaviors_list,\n",
        "           print_types=table_metrics_to_print,\n",
        "           lines_to_include=[5, 6, 7, 8, 9],\n",
        "           columns_to_include=[0, 1, 2, 3, 4])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOHBP8ZYc6JR",
        "outputId": "bef98443-46cc-4286-90be-cccdaf8704f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The probability of a behavior to onset an affect - all students\n",
            "Number of students:  30\n",
            "Students ids:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
            "Prev\\Next;ENG;CON;FRU;BOR;OTH\n",
            "ON_TASK;0.1620 (0.0011)  [2130]  {1.0} ;0.1700 (0.0000)  [664]  {1.0} ;0.0343 (0.0059)  [69]  {1.0} ;0.0238 (0.0002)  [98]  {1.0} ;0.1996 (0.0000)  [183]  {1.0} ;\n",
            "ON_SYSTEM;0.6471 (0.0000)  [170]  {1.0} ;-0.0535 (0.0008)  [158]  {1.0} ;0.0004 (0.0001)  [88]  {1.0} ;0.0193 (0.0347)  [120]  {1.0} ;0.0411 (0.5503)  [366]  {0.0} ;\n",
            "ON_TASK_RES;0.6015 (0.0001)  [328]  {1.0} ;0.1304 (0.4225)  [42]  {0.0} ;-0.0158 (0.0000)  [0]  {1.0} ;-0.0173 (0.0006)  [1]  {1.0} ;-0.0198 (0.0619)  [9]  {0.0} ;\n",
            "OFF_TASK;0.4471 (0.0000)  [115]  {1.0} ;0.0595 (0.9462)  [49]  {0.0} ;-0.0204 (0.0000)  [8]  {1.0} ;0.0756 (0.6455)  [52]  {0.0} ;0.0681 (0.9145)  [428]  {0.0} ;\n",
            "ON_TASK_CONV;0.4118 (0.0021)  [102]  {1.0} ;0.0861 (0.6310)  [267]  {0.0} ;0.0305 (0.3427)  [12]  {0.0} ;-0.0260 (0.0000)  [1]  {1.0} ;0.1183 (0.4657)  [28]  {0.0} ;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The probability of a behavior to onset an affect - female students\")\n",
        "\n",
        "# it computes the list of students to be included in the analysis \n",
        "students_to_include_list = compute_students_to_include( students_amount=30,\n",
        "                                                        gender_filter=True,\n",
        "                                                        gender_text=\"F\",\n",
        "                                                        show_info=True)\n",
        "\n",
        "# it computes the list of emotions labels to be considered according to the list of students\n",
        "transitions_list = compute_list_of_emotion_labels(students_to_include=students_to_include_list,\n",
        "                                                  consider_emotion_duration=False,\n",
        "                                                  filter_emotion_duration=False,\n",
        "                                                  emotion_to_filter_text=\"ENG\",\n",
        "                                                  duration_greater_than=True,\n",
        "                                                  duration_threshold_method=\"mean\",\n",
        "                                                  show_info=False)\n",
        "\n",
        "# based on the list of emotions labels, it computes the L metric matrix and the averaged L matrix\n",
        "L_metric_results, L_metric_average_results = compute_statistic(seq_list=transitions_list,\n",
        "                                                               states=emotions_behaviors_list, \n",
        "                                                               L_star=False, \n",
        "                                                               use_mean_rates=False)\n",
        "\n",
        "# compute the p values for each transition according to the L matrix and the average L matrix\n",
        "p_values_matrix = calculate_p_values(states_list=emotions_behaviors_list, \n",
        "                                     L_metric_average_results=L_metric_average_results, \n",
        "                                     level_at_change=L_metric_at_chance_threshold)\n",
        "\n",
        "# compute the t test adjustment according to the BH post hoc method \n",
        "multiple_tests_matrix, multiple_tests_reject_matrix = calculate_multiple_t_test_adjustment(states_list=emotions_behaviors_list, \n",
        "                                                                                           matrix_p_values=p_values_matrix)\n",
        "\n",
        "# compute the emotion transitions count\n",
        "emotion_counts = get_emotion_transitions_counts(list_seq=transitions_list, \n",
        "                                                states=emotions_behaviors_list)\n",
        "\n",
        "\n",
        "# print the results according to the predefined metrics\n",
        "print_vals(L_metric_results, \n",
        "           p_values_matrix, \n",
        "           multiple_tests_matrix, \n",
        "           multiple_tests_reject_matrix, \n",
        "           emotion_counts, \n",
        "           emotions_behaviors_list,\n",
        "           print_types=table_metrics_to_print,\n",
        "           lines_to_include=[5, 6, 7, 8, 9],\n",
        "           columns_to_include=[0, 1, 2, 3, 4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "praDUl4F6R6j",
        "outputId": "eead0182-491b-45de-df0e-fd832df8962b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The probability of a behavior to onset an affect - female students\n",
            "Number of students:  16\n",
            "Students ids:  [1, 2, 6, 9, 11, 13, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27]\n",
            "Prev\\Next;ENG;CON;FRU;BOR;OTH\n",
            "ON_TASK;0.1564 (0.0073)  [1204]  {1.0} ;0.1720 (0.0005)  [268]  {1.0} ;0.0354 (0.0857)  [35]  {0.0} ;0.0244 (0.0026)  [47]  {1.0} ;0.1984 (0.0003)  [80]  {1.0} ;\n",
            "ON_SYSTEM;0.5936 (0.0001)  [60]  {1.0} ;-0.0280 (0.0897)  [141]  {0.0} ;-0.0191 (0.0000)  [85]  {1.0} ;0.0428 (0.5594)  [98]  {0.0} ;0.0607 (0.9695)  [202]  {0.0} ;\n",
            "ON_TASK_RES;0.6784 (0.0010)  [162]  {1.0} ;0.0501 (0.8647)  [23]  {0.0} ;-0.0147 (0.0000)  [0]  {1.0} ;-0.0079 (0.0803)  [1]  {0.0} ;-0.0226 (0.1468)  [6]  {0.0} ;\n",
            "OFF_TASK;0.5286 (0.0001)  [75]  {1.0} ;0.1245 (0.3693)  [42]  {0.0} ;-0.0204 (0.0000)  [5]  {1.0} ;0.0589 (0.9032)  [31]  {0.0} ;-0.0439 (0.0002)  [201]  {1.0} ;\n",
            "ON_TASK_CONV;0.4345 (0.0085)  [43]  {1.0} ;0.0957 (0.6430)  [152]  {0.0} ;0.0182 (0.1146)  [6]  {0.0} ;-0.0296 (0.0000)  [1]  {1.0} ;0.1016 (0.5746)  [23]  {0.0} ;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The probability of a behavior to onset an affect - male students\")\n",
        "\n",
        "# it computes the list of students to be included in the analysis \n",
        "students_to_include_list = compute_students_to_include( students_amount=30,\n",
        "                                                        gender_filter=True,\n",
        "                                                        gender_text=\"M\",\n",
        "                                                        show_info=True)\n",
        "\n",
        "# it computes the list of emotions labels to be considered according to the list of students\n",
        "transitions_list = compute_list_of_emotion_labels(students_to_include=students_to_include_list,\n",
        "                                                  consider_emotion_duration=False,\n",
        "                                                  filter_emotion_duration=False,\n",
        "                                                  emotion_to_filter_text=\"ENG\",\n",
        "                                                  duration_greater_than=True,\n",
        "                                                  duration_threshold_method=\"mean\",\n",
        "                                                  show_info=False)\n",
        "\n",
        "# based on the list of emotions labels, it computes the L metric matrix and the averaged L matrix\n",
        "L_metric_results, L_metric_average_results = compute_statistic(seq_list=transitions_list,\n",
        "                                                               states=emotions_behaviors_list, \n",
        "                                                               L_star=False, \n",
        "                                                               use_mean_rates=False)\n",
        "\n",
        "# compute the p values for each transition according to the L matrix and the average L matrix\n",
        "p_values_matrix = calculate_p_values(states_list=emotions_behaviors_list, \n",
        "                                     L_metric_average_results=L_metric_average_results, \n",
        "                                     level_at_change=L_metric_at_chance_threshold)\n",
        "\n",
        "# compute the t test adjustment according to the BH post hoc method \n",
        "multiple_tests_matrix, multiple_tests_reject_matrix = calculate_multiple_t_test_adjustment(states_list=emotions_behaviors_list, \n",
        "                                                                                           matrix_p_values=p_values_matrix)\n",
        "\n",
        "# compute the emotion transitions count\n",
        "emotion_counts = get_emotion_transitions_counts(list_seq=transitions_list, \n",
        "                                                states=emotions_behaviors_list)\n",
        "\n",
        "\n",
        "# print the results according to the predefined metrics\n",
        "print_vals(L_metric_results, \n",
        "           p_values_matrix, \n",
        "           multiple_tests_matrix, \n",
        "           multiple_tests_reject_matrix, \n",
        "           emotion_counts, \n",
        "           emotions_behaviors_list,\n",
        "           print_types=table_metrics_to_print,\n",
        "           lines_to_include=[5, 6, 7, 8, 9],\n",
        "           columns_to_include=[0, 1, 2, 3, 4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qr36Z3kp6doh",
        "outputId": "bd94db9c-10cd-40ce-d46d-43ef659b0a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The probability of a behavior to onset an affect - male students\n",
            "Number of students:  14\n",
            "Students ids:  [3, 4, 5, 7, 8, 10, 12, 14, 15, 16, 25, 28, 29, 30]\n",
            "Prev\\Next;ENG;CON;FRU;BOR;OTH\n",
            "ON_TASK;0.1685 (0.0483)  [926]  {1.0} ;0.1678 (0.0108)  [396]  {1.0} ;0.0330 (0.0294)  [34]  {1.0} ;0.0231 (0.0292)  [51]  {1.0} ;0.2010 (0.0035)  [103]  {1.0} ;\n",
            "ON_SYSTEM;0.7130 (0.0000)  [110]  {1.0} ;-0.0849 (0.0005)  [17]  {1.0} ;0.0244 (0.2006)  [3]  {0.0} ;-0.0096 (0.0001)  [22]  {1.0} ;0.0170 (0.4272)  [164]  {0.0} ;\n",
            "ON_TASK_RES;0.5160 (0.0307)  [166]  {1.0} ;0.2197 (0.3437)  [19]  {0.0} ;-0.0171 (0.0000)  [0]  {1.0} ;-0.0277 (0.0001)  [0]  {1.0} ;-0.0168 (0.2730)  [3]  {0.0} ;\n",
            "OFF_TASK;0.3531 (0.0355)  [40]  {0.0} ;-0.0156 (0.1546)  [7]  {0.0} ;-0.0205 (0.0000)  [3]  {1.0} ;0.0950 (0.5389)  [21]  {0.0} ;0.1972 (0.1941)  [227]  {0.0} ;\n",
            "ON_TASK_CONV;0.3795 (0.1267)  [59]  {0.0} ;0.0723 (0.8907)  [115]  {0.0} ;0.0482 (0.8532)  [6]  {0.0} ;-0.0208 (0.0000)  [0]  {1.0} ;0.1422 (0.6407)  [5]  {0.0} ;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Execution 6: Co-occurrence between behaviors and affect\n",
        "---\n",
        "This part of the code executes the previous defined functions and set the paremeters to calculate the co-occurrence between behaviors and affect, considering the data from all the students.\n"
      ],
      "metadata": {
        "id": "Xf8YTFowd5T3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The probability of co-occurrence betwen behaviors and affects - all students\")\n",
        "\n",
        "# variable to define whether the coocurrence calculation is enabled\n",
        "consider_affect_behaviors_cooccurence=True\n",
        "\n",
        "# it computes the list of students to be included in the analysis \n",
        "students_to_include_list = compute_students_to_include( students_amount=30,\n",
        "                                                        gender_filter=False,\n",
        "                                                        gender_text=\"M\",\n",
        "                                                        show_info=True)\n",
        "\n",
        "# it computes the list of emotions labels to be considered according to the list of students\n",
        "transitions_list = compute_list_of_emotion_labels(students_to_include=students_to_include_list,\n",
        "                                                  consider_emotion_duration=False,\n",
        "                                                  filter_emotion_duration=False,\n",
        "                                                  emotion_to_filter_text=\"ENG\",\n",
        "                                                  duration_greater_than=True,\n",
        "                                                  duration_threshold_method=\"mean\",\n",
        "                                                  show_info=False)\n",
        "\n",
        "# based on the list of emotions labels, it computes the L metric matrix and the averaged L matrix\n",
        "L_metric_results, L_metric_average_results = compute_statistic(seq_list=transitions_list,\n",
        "                                                               states=emotions_behaviors_list, \n",
        "                                                               L_star=False, \n",
        "                                                               use_mean_rates=False,\n",
        "                                                               consider_affect_behaviors_cooccurence=consider_affect_behaviors_cooccurence)\n",
        "\n",
        "# compute the p values for each transition according to the L matrix and the average L matrix\n",
        "p_values_matrix = calculate_p_values(states_list=emotions_behaviors_list, \n",
        "                                     L_metric_average_results=L_metric_average_results, \n",
        "                                     level_at_change=L_metric_at_chance_threshold)\n",
        "\n",
        "# compute the t test adjustment according to the BH post hoc method \n",
        "multiple_tests_matrix, multiple_tests_reject_matrix = calculate_multiple_t_test_adjustment(states_list=emotions_behaviors_list, \n",
        "                                                                                           matrix_p_values=p_values_matrix)\n",
        "\n",
        "# compute the emotion transitions count\n",
        "emotion_counts = get_emotion_transitions_counts(list_seq=transitions_list, \n",
        "                                                states=emotions_behaviors_list)\n",
        "\n",
        "\n",
        "# print the results according to the predefined metrics\n",
        "print_vals(L_metric_results, \n",
        "           p_values_matrix, \n",
        "           multiple_tests_matrix, \n",
        "           multiple_tests_reject_matrix, \n",
        "           emotion_counts, \n",
        "           emotions_behaviors_list,\n",
        "           print_types=table_metrics_to_print,\n",
        "           lines_to_include=[5, 6, 7, 8, 9],\n",
        "           columns_to_include=[0, 1, 2, 3, 4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMZ2gvb2d5xJ",
        "outputId": "b865a397-e5f0-458a-ce10-be632795bd38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The probability of co-occurrence betwen behaviors and affects - all students\n",
            "Number of students:  30\n",
            "Students ids:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3622: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:195: RuntimeWarning: invalid value encountered in true_divide\n",
            "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prev\\Next;ENG;CON;FRU;BOR;OTH\n",
            "ON_TASK;0.6402 (0.0000)  [2130]  {1.0} ;0.2422 (0.0000)  [664]  {1.0} ;0.0482 (0.2367)  [69]  {0.0} ;0.0361 (0.0079)  [98]  {1.0} ;0.0333 (0.0034)  [183]  {1.0} ;\n",
            "ON_SYSTEM;0.1845 (0.0213)  [170]  {1.0} ;0.0549 (0.7645)  [158]  {0.0} ;0.0211 (0.0036)  [88]  {1.0} ;0.1533 (0.0116)  [120]  {1.0} ;0.5863 (0.0000)  [366]  {1.0} ;\n",
            "ON_TASK_RES;0.8187 (0.0000)  [328]  {1.0} ;0.1401 (0.1152)  [42]  {0.0} ;0.0000 (0.0000)  [0]  {1.0} ;0.0175 (0.0196)  [1]  {1.0} ;0.0237 (0.0292)  [9]  {1.0} ;\n",
            "OFF_TASK;0.0811 (0.5065)  [115]  {0.0} ;0.0718 (0.8090)  [49]  {0.0} ;0.0234 (0.0061)  [8]  {1.0} ;0.0662 (0.8561)  [52]  {0.0} ;0.7575 (0.0000)  [428]  {1.0} ;\n",
            "ON_TASK_CONV;0.1477 (0.1068)  [102]  {0.0} ;0.6628 (0.0000)  [267]  {1.0} ;0.1053 (0.3788)  [12]  {0.0} ;0.0000 (0.0000)  [1]  {1.0} ;0.0842 (0.5652)  [28]  {0.0} ;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The probability of co-occurrence betwen behaviors and affects - female students\")\n",
        "\n",
        "# variable to define whether the coocurrence calculation is enabled\n",
        "consider_affect_behaviors_cooccurence=True\n",
        "\n",
        "# it computes the list of students to be included in the analysis \n",
        "students_to_include_list = compute_students_to_include( students_amount=30,\n",
        "                                                        gender_filter=True,\n",
        "                                                        gender_text=\"F\",\n",
        "                                                        show_info=True)\n",
        "\n",
        "# it computes the list of emotions labels to be considered according to the list of students\n",
        "transitions_list = compute_list_of_emotion_labels(students_to_include=students_to_include_list,\n",
        "                                                  consider_emotion_duration=False,\n",
        "                                                  filter_emotion_duration=False,\n",
        "                                                  emotion_to_filter_text=\"ENG\",\n",
        "                                                  duration_greater_than=True,\n",
        "                                                  duration_threshold_method=\"mean\",\n",
        "                                                  show_info=False)\n",
        "\n",
        "# based on the list of emotions labels, it computes the L metric matrix and the averaged L matrix\n",
        "L_metric_results, L_metric_average_results = compute_statistic(seq_list=transitions_list,\n",
        "                                                               states=emotions_behaviors_list, \n",
        "                                                               L_star=False, \n",
        "                                                               use_mean_rates=False,\n",
        "                                                               consider_affect_behaviors_cooccurence=consider_affect_behaviors_cooccurence)\n",
        "\n",
        "# compute the p values for each transition according to the L matrix and the average L matrix\n",
        "p_values_matrix = calculate_p_values(states_list=emotions_behaviors_list, \n",
        "                                     L_metric_average_results=L_metric_average_results, \n",
        "                                     level_at_change=L_metric_at_chance_threshold)\n",
        "\n",
        "# compute the t test adjustment according to the BH post hoc method \n",
        "multiple_tests_matrix, multiple_tests_reject_matrix = calculate_multiple_t_test_adjustment(states_list=emotions_behaviors_list, \n",
        "                                                                                           matrix_p_values=p_values_matrix)\n",
        "\n",
        "# compute the emotion transitions count\n",
        "emotion_counts = get_emotion_transitions_counts(list_seq=transitions_list, \n",
        "                                                states=emotions_behaviors_list)\n",
        "\n",
        "\n",
        "# print the results according to the predefined metrics\n",
        "print_vals(L_metric_results, \n",
        "           p_values_matrix, \n",
        "           multiple_tests_matrix, \n",
        "           multiple_tests_reject_matrix, \n",
        "           emotion_counts, \n",
        "           emotions_behaviors_list,\n",
        "           print_types=table_metrics_to_print,\n",
        "           lines_to_include=[5, 6, 7, 8, 9],\n",
        "           columns_to_include=[0, 1, 2, 3, 4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-c0ypsX65Pp",
        "outputId": "14657e88-4cef-45e2-dbe3-a301114c8b0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The probability of co-occurrence betwen behaviors and affects - female students\n",
            "Number of students:  16\n",
            "Students ids:  [1, 2, 6, 9, 11, 13, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27]\n",
            "Prev\\Next;ENG;CON;FRU;BOR;OTH\n",
            "ON_TASK;0.6627 (0.0000)  [1204]  {1.0} ;0.2421"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3622: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:195: RuntimeWarning: invalid value encountered in true_divide\n",
            "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " (0.0001)  [268]  {1.0} ;0.0427 (0.2100)  [35]  {0.0} ;0.0320 (0.0362)  [47]  {1.0} ;0.0205 (0.0021)  [80]  {1.0} ;\n",
            "ON_SYSTEM;0.1031 (0.4161)  [60]  {0.0} ;0.0833 (0.6404)  [141]  {0.0} ;0.0312 (0.1881)  [85]  {0.0} ;0.2229 (0.0047)  [98]  {1.0} ;0.5594 (0.0000)  [202]  {1.0} ;\n",
            "ON_TASK_RES;0.8517 (0.0000)  [162]  {1.0} ;0.0700 (0.8479)  [23]  {0.0} ;0.0000 (0.0000)  [0]  {1.0} ;0.0333 (0.4043)  [1]  {0.0} ;0.0450 (0.5769)  [6]  {0.0} ;\n",
            "OFF_TASK;0.0789 (0.7075)  [75]  {0.0} ;0.1341 (0.3128)  [42]  {0.0} ;0.0296 (0.1734)  [5]  {0.0} ;0.0716 (0.7580)  [31]  {0.0} ;0.6857 (0.0000)  [201]  {1.0} ;\n",
            "ON_TASK_CONV;0.1235 (0.3488)  [43]  {0.0} ;0.7168 (0.0000)  [152]  {1.0} ;0.0791 (0.7532)  [6]  {0.0} ;0.0000 (0.0000)  [1]  {1.0} ;0.0806 (0.6782)  [23]  {0.0} ;\n"
          ]
        }
      ]
    }
  ]
}